{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lit_5UraKpcH",
        "outputId": "797626f9-ca43-42ad-a5b7-35a1db79967d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t24Eg2puj1t",
        "outputId": "bec8ac35-fc66-45ed-e2d4-cb99d1b77e9d"
      },
      "source": [
        "!mkdir data\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/extracted_features.npy\"\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels.npy\"\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/features_stretched.npy\"\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels_stretched.npy\"\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/features_pitch_shifted.npy\"\n",
        "!cd data && wget \"http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels_pitch_shifted.npy\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-23 11:00:45--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/extracted_features.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126886528 (121M) [application/octet-stream]\n",
            "Saving to: ‘extracted_features.npy’\n",
            "\n",
            "extracted_features. 100%[===================>] 121.01M  22.8MB/s    in 6.0s    \n",
            "\n",
            "2020-12-23 11:00:52 (20.1 MB/s) - ‘extracted_features.npy’ saved [126886528/126886528]\n",
            "\n",
            "--2020-12-23 11:00:52--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51648 (50K) [application/octet-stream]\n",
            "Saving to: ‘labels.npy’\n",
            "\n",
            "labels.npy          100%[===================>]  50.44K   263KB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 11:00:52 (263 KB/s) - ‘labels.npy’ saved [51648/51648]\n",
            "\n",
            "--2020-12-23 11:00:52--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/features_stretched.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70063488 (67M) [application/octet-stream]\n",
            "Saving to: ‘features_stretched.npy’\n",
            "\n",
            "features_stretched. 100%[===================>]  66.82M  21.0MB/s    in 3.5s    \n",
            "\n",
            "2020-12-23 11:00:56 (18.8 MB/s) - ‘features_stretched.npy’ saved [70063488/70063488]\n",
            "\n",
            "--2020-12-23 11:00:56--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels_stretched.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28576 (28K) [application/octet-stream]\n",
            "Saving to: ‘labels_stretched.npy’\n",
            "\n",
            "labels_stretched.np 100%[===================>]  27.91K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-12-23 11:00:56 (299 KB/s) - ‘labels_stretched.npy’ saved [28576/28576]\n",
            "\n",
            "--2020-12-23 11:00:56--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/features_pitch_shifted.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140126848 (134M) [application/octet-stream]\n",
            "Saving to: ‘features_pitch_shifted.npy’\n",
            "\n",
            "features_pitch_shif 100%[===================>] 133.63M  22.6MB/s    in 6.5s    \n",
            "\n",
            "2020-12-23 11:01:03 (20.5 MB/s) - ‘features_pitch_shifted.npy’ saved [140126848/140126848]\n",
            "\n",
            "--2020-12-23 11:01:03--  http://164.68.116.174:5000/download/files/isep/a3/deep-learning/respiratory-sound/labels_pitch_shifted.npy\n",
            "Connecting to 164.68.116.174:5000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57024 (56K) [application/octet-stream]\n",
            "Saving to: ‘labels_pitch_shifted.npy’\n",
            "\n",
            "labels_pitch_shifte 100%[===================>]  55.69K   293KB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 11:01:03 (293 KB/s) - ‘labels_pitch_shifted.npy’ saved [57024/57024]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H0r9MmUKMAl"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OWISyu7KMAu"
      },
      "source": [
        "origin_features, origin_labels = np.load('/content/data/extracted_features.npy'), np.load('/content/data/labels.npy')\n",
        "origin_features = np.delete(origin_features, np.where((origin_labels == 'Asthma') | (origin_labels == 'LRTI'))[0], axis=0)\n",
        "origin_labels = np.delete(origin_labels, np.where((origin_labels == 'Asthma') | (origin_labels == 'LRTI'))[0], axis=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQoKyk4rY4Ii"
      },
      "source": [
        "features_stretched, labels_stretched = np.load('/content/data/features_stretched.npy'), np.load('/content/data/labels_stretched.npy')\n",
        "features_stretched = np.delete(features_stretched, np.where((labels_stretched == 'Asthma') | (labels_stretched == 'LRTI'))[0], axis=0)\n",
        "labels_stretched = np.delete(labels_stretched, np.where((labels_stretched == 'Asthma') | (labels_stretched == 'LRTI'))[0], axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q24RqRLYH5cz"
      },
      "source": [
        "features_pitch_shifted, labels_pitch_shifted = np.load('/content/data/features_pitch_shifted.npy'), np.load('/content/data/labels_pitch_shifted.npy')\n",
        "features_pitch_shifted = np.delete(features_pitch_shifted, np.where((labels_pitch_shifted == 'Asthma') | (labels_pitch_shifted == 'LRTI'))[0], axis=0)\n",
        "labels_pitch_shifted = np.delete(labels_pitch_shifted, np.where((labels_pitch_shifted == 'Asthma') | (labels_pitch_shifted == 'LRTI'))[0], axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTtyS_MLZeVt"
      },
      "source": [
        "features = np.concatenate((origin_features, features_stretched), axis=0)\n",
        "features = np.concatenate((features, features_pitch_shifted), axis=0)\n",
        "labels = np.concatenate((origin_labels,labels_stretched), axis=0)\n",
        "labels = np.concatenate((labels,labels_pitch_shifted), axis=0)\n",
        "classes = ['COPD', 'Pneumonia', 'Healthy', 'URTI', 'Bronchiectasis', 'Bronchiolitis']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onPCuTqVKMAv"
      },
      "source": [
        "le = LabelEncoder()\n",
        "i_labels = le.fit_transform(labels)\n",
        "oh_labels = to_categorical(i_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DNSks3eKMAw"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(features, oh_labels, stratify=oh_labels, test_size=0.2, random_state=42)\n",
        "num_rows, num_columns, num_channels = 40, 862, 1  # input shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKs2zzJkKMAw"
      },
      "source": [
        "num_labels = oh_labels.shape[1]\n",
        "filter_size = 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8lOly6xKMAw",
        "outputId": "47ff23cf-5822-4fbd-e887-f08f38c163fe"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=filter_size, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 39, 861, 16)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 19, 430, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 19, 430, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 18, 429, 32)       2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 9, 214, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9, 214, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 213, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 106, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 106, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 105, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 52, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 52, 128)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 44,086\n",
            "Trainable params: 44,086\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxx4zmjKKMAy"
      },
      "source": [
        "num_epochs = 250\n",
        "num_batch_size = 64\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='mymodel2_{epoch:02d}.h5',\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        verbose=1)\n",
        "]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUk-hqCyKMAy",
        "outputId": "7cb5a26e-ccff-40d2-9023-43c3e7c3546e"
      },
      "source": [
        "model.fit(np.expand_dims(x_train, axis=3), y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(np.expand_dims(x_test, axis=3), y_test), callbacks=callbacks, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "31/31 [==============================] - 10s 56ms/step - loss: 6.8929 - accuracy: 0.2537 - val_loss: 1.6438 - val_accuracy: 0.3222\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32225, saving model to mymodel2_01.h5\n",
            "Epoch 2/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 1.5841 - accuracy: 0.4155 - val_loss: 1.4170 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.32225 to 0.50104, saving model to mymodel2_02.h5\n",
            "Epoch 3/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 1.2881 - accuracy: 0.5050 - val_loss: 1.3329 - val_accuracy: 0.4927\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.50104\n",
            "Epoch 4/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 1.2057 - accuracy: 0.5408 - val_loss: 1.3240 - val_accuracy: 0.4678\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.50104\n",
            "Epoch 5/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 1.1042 - accuracy: 0.5753 - val_loss: 1.3317 - val_accuracy: 0.4532\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.50104\n",
            "Epoch 6/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 1.0367 - accuracy: 0.6088 - val_loss: 1.2196 - val_accuracy: 0.4657\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.50104\n",
            "Epoch 7/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 1.0338 - accuracy: 0.6287 - val_loss: 1.2675 - val_accuracy: 0.4387\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.50104\n",
            "Epoch 8/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.9582 - accuracy: 0.6419 - val_loss: 1.1597 - val_accuracy: 0.5405\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.50104 to 0.54054, saving model to mymodel2_08.h5\n",
            "Epoch 9/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.9866 - accuracy: 0.6360 - val_loss: 1.2124 - val_accuracy: 0.4407\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.54054\n",
            "Epoch 10/250\n",
            "31/31 [==============================] - 1s 39ms/step - loss: 0.8788 - accuracy: 0.6634 - val_loss: 1.2134 - val_accuracy: 0.4387\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.54054\n",
            "Epoch 11/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.8418 - accuracy: 0.6775 - val_loss: 1.2250 - val_accuracy: 0.4407\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.54054\n",
            "Epoch 12/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.8294 - accuracy: 0.6841 - val_loss: 1.0239 - val_accuracy: 0.5676\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.54054 to 0.56757, saving model to mymodel2_12.h5\n",
            "Epoch 13/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.8007 - accuracy: 0.7065 - val_loss: 1.1033 - val_accuracy: 0.5010\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.56757\n",
            "Epoch 14/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.7438 - accuracy: 0.7060 - val_loss: 1.0546 - val_accuracy: 0.5593\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.56757\n",
            "Epoch 15/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.7777 - accuracy: 0.6943 - val_loss: 0.8965 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.56757 to 0.67568, saving model to mymodel2_15.h5\n",
            "Epoch 16/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.8357 - accuracy: 0.6707 - val_loss: 0.8829 - val_accuracy: 0.6944\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.67568 to 0.69439, saving model to mymodel2_16.h5\n",
            "Epoch 17/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.7033 - accuracy: 0.7284 - val_loss: 0.9001 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.69439 to 0.70270, saving model to mymodel2_17.h5\n",
            "Epoch 18/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.6487 - accuracy: 0.7499 - val_loss: 0.8968 - val_accuracy: 0.6528\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.70270\n",
            "Epoch 19/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.6839 - accuracy: 0.7425 - val_loss: 0.7775 - val_accuracy: 0.7006\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.70270\n",
            "Epoch 20/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.6193 - accuracy: 0.7492 - val_loss: 0.7764 - val_accuracy: 0.7214\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.70270 to 0.72141, saving model to mymodel2_20.h5\n",
            "Epoch 21/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.6155 - accuracy: 0.7512 - val_loss: 0.8107 - val_accuracy: 0.6985\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.72141\n",
            "Epoch 22/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.6135 - accuracy: 0.7461 - val_loss: 0.7691 - val_accuracy: 0.6881\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.72141\n",
            "Epoch 23/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.6301 - accuracy: 0.7442 - val_loss: 0.8289 - val_accuracy: 0.6881\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.72141\n",
            "Epoch 24/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5836 - accuracy: 0.7643 - val_loss: 0.7395 - val_accuracy: 0.7235\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.72141 to 0.72349, saving model to mymodel2_24.h5\n",
            "Epoch 25/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.5543 - accuracy: 0.7775 - val_loss: 0.7182 - val_accuracy: 0.6985\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.72349\n",
            "Epoch 26/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.5617 - accuracy: 0.7708 - val_loss: 0.6810 - val_accuracy: 0.7235\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.72349\n",
            "Epoch 27/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5328 - accuracy: 0.7817 - val_loss: 0.6561 - val_accuracy: 0.7422\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.72349 to 0.74220, saving model to mymodel2_27.h5\n",
            "Epoch 28/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5158 - accuracy: 0.7937 - val_loss: 0.6523 - val_accuracy: 0.7505\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.74220 to 0.75052, saving model to mymodel2_28.h5\n",
            "Epoch 29/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5651 - accuracy: 0.7630 - val_loss: 0.6752 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.75052\n",
            "Epoch 30/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.5317 - accuracy: 0.8019 - val_loss: 0.6936 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.75052\n",
            "Epoch 31/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.5157 - accuracy: 0.7950 - val_loss: 0.6554 - val_accuracy: 0.7318\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.75052\n",
            "Epoch 32/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.5746 - accuracy: 0.7690 - val_loss: 0.6886 - val_accuracy: 0.7152\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.75052\n",
            "Epoch 33/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5094 - accuracy: 0.7975 - val_loss: 0.6477 - val_accuracy: 0.7630\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.75052 to 0.76299, saving model to mymodel2_33.h5\n",
            "Epoch 34/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.5150 - accuracy: 0.7961 - val_loss: 0.6811 - val_accuracy: 0.7339\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.76299\n",
            "Epoch 35/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.4640 - accuracy: 0.8150 - val_loss: 0.6300 - val_accuracy: 0.7401\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.76299\n",
            "Epoch 36/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4375 - accuracy: 0.8259 - val_loss: 0.6881 - val_accuracy: 0.7339\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.76299\n",
            "Epoch 37/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.4028 - accuracy: 0.8471 - val_loss: 0.6998 - val_accuracy: 0.7235\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.76299\n",
            "Epoch 38/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4686 - accuracy: 0.7973 - val_loss: 0.6846 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.76299\n",
            "Epoch 39/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4230 - accuracy: 0.8388 - val_loss: 0.6958 - val_accuracy: 0.7277\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.76299\n",
            "Epoch 40/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4870 - accuracy: 0.7931 - val_loss: 0.6135 - val_accuracy: 0.7193\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.76299\n",
            "Epoch 41/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.4150 - accuracy: 0.8444 - val_loss: 0.6213 - val_accuracy: 0.7380\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.76299\n",
            "Epoch 42/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3856 - accuracy: 0.8492 - val_loss: 0.6302 - val_accuracy: 0.7297\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.76299\n",
            "Epoch 43/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4882 - accuracy: 0.8011 - val_loss: 0.5192 - val_accuracy: 0.7838\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.76299 to 0.78378, saving model to mymodel2_43.h5\n",
            "Epoch 44/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.3657 - accuracy: 0.8562 - val_loss: 0.5698 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.78378\n",
            "Epoch 45/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3918 - accuracy: 0.8486 - val_loss: 0.5649 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.78378 to 0.79210, saving model to mymodel2_45.h5\n",
            "Epoch 46/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4157 - accuracy: 0.8432 - val_loss: 0.6082 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.79210\n",
            "Epoch 47/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3842 - accuracy: 0.8496 - val_loss: 0.4909 - val_accuracy: 0.8067\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.79210 to 0.80665, saving model to mymodel2_47.h5\n",
            "Epoch 48/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3435 - accuracy: 0.8613 - val_loss: 0.5712 - val_accuracy: 0.7547\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.80665\n",
            "Epoch 49/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3421 - accuracy: 0.8700 - val_loss: 0.5699 - val_accuracy: 0.7713\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.80665\n",
            "Epoch 50/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4170 - accuracy: 0.8326 - val_loss: 0.6425 - val_accuracy: 0.7609\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.80665\n",
            "Epoch 51/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3927 - accuracy: 0.8422 - val_loss: 0.6043 - val_accuracy: 0.7879\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.80665\n",
            "Epoch 52/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.3466 - accuracy: 0.8713 - val_loss: 0.5481 - val_accuracy: 0.7630\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.80665\n",
            "Epoch 53/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3086 - accuracy: 0.8802 - val_loss: 0.4852 - val_accuracy: 0.8067\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.80665\n",
            "Epoch 54/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3030 - accuracy: 0.8858 - val_loss: 0.4732 - val_accuracy: 0.8191\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.80665 to 0.81913, saving model to mymodel2_54.h5\n",
            "Epoch 55/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.3103 - accuracy: 0.8753 - val_loss: 0.6482 - val_accuracy: 0.7755\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.81913\n",
            "Epoch 56/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.3081 - accuracy: 0.8813 - val_loss: 0.5191 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.81913\n",
            "Epoch 57/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3348 - accuracy: 0.8768 - val_loss: 0.5214 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.81913\n",
            "Epoch 58/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.4692 - accuracy: 0.8200 - val_loss: 0.4656 - val_accuracy: 0.7942\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.81913\n",
            "Epoch 59/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3040 - accuracy: 0.8801 - val_loss: 0.5064 - val_accuracy: 0.7672\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.81913\n",
            "Epoch 60/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3487 - accuracy: 0.8664 - val_loss: 0.5420 - val_accuracy: 0.7963\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.81913\n",
            "Epoch 61/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.2995 - accuracy: 0.8909 - val_loss: 0.4100 - val_accuracy: 0.8420\n",
            "\n",
            "Epoch 00061: val_accuracy improved from 0.81913 to 0.84200, saving model to mymodel2_61.h5\n",
            "Epoch 62/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.2781 - accuracy: 0.8950 - val_loss: 0.6166 - val_accuracy: 0.7609\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.84200\n",
            "Epoch 63/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2687 - accuracy: 0.9011 - val_loss: 0.5319 - val_accuracy: 0.8191\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.84200\n",
            "Epoch 64/250\n",
            "31/31 [==============================] - 1s 39ms/step - loss: 0.2776 - accuracy: 0.8892 - val_loss: 0.4539 - val_accuracy: 0.7963\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.84200\n",
            "Epoch 65/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3041 - accuracy: 0.8892 - val_loss: 0.3508 - val_accuracy: 0.8565\n",
            "\n",
            "Epoch 00065: val_accuracy improved from 0.84200 to 0.85655, saving model to mymodel2_65.h5\n",
            "Epoch 66/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2556 - accuracy: 0.9058 - val_loss: 0.4485 - val_accuracy: 0.8087\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.85655\n",
            "Epoch 67/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2580 - accuracy: 0.8989 - val_loss: 0.4288 - val_accuracy: 0.8108\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.85655\n",
            "Epoch 68/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2278 - accuracy: 0.9147 - val_loss: 0.5927 - val_accuracy: 0.7630\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.85655\n",
            "Epoch 69/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.3382 - accuracy: 0.8681 - val_loss: 0.4386 - val_accuracy: 0.8254\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.85655\n",
            "Epoch 70/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2086 - accuracy: 0.9219 - val_loss: 0.3903 - val_accuracy: 0.8337\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.85655\n",
            "Epoch 71/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1919 - accuracy: 0.9308 - val_loss: 0.4136 - val_accuracy: 0.8191\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.85655\n",
            "Epoch 72/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1921 - accuracy: 0.9246 - val_loss: 0.5315 - val_accuracy: 0.8337\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.85655\n",
            "Epoch 73/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2770 - accuracy: 0.8814 - val_loss: 0.3778 - val_accuracy: 0.8503\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.85655\n",
            "Epoch 74/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2672 - accuracy: 0.9026 - val_loss: 0.4272 - val_accuracy: 0.8358\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.85655\n",
            "Epoch 75/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2055 - accuracy: 0.9238 - val_loss: 0.3126 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00075: val_accuracy improved from 0.85655 to 0.87942, saving model to mymodel2_75.h5\n",
            "Epoch 76/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2471 - accuracy: 0.9119 - val_loss: 0.3633 - val_accuracy: 0.8753\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.87942\n",
            "Epoch 77/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1907 - accuracy: 0.9276 - val_loss: 0.5373 - val_accuracy: 0.7942\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.87942\n",
            "Epoch 78/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2925 - accuracy: 0.8832 - val_loss: 0.3138 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00078: val_accuracy improved from 0.87942 to 0.88358, saving model to mymodel2_78.h5\n",
            "Epoch 79/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1849 - accuracy: 0.9263 - val_loss: 0.2928 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00079: val_accuracy improved from 0.88358 to 0.89813, saving model to mymodel2_79.h5\n",
            "Epoch 80/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1917 - accuracy: 0.9227 - val_loss: 0.4092 - val_accuracy: 0.8295\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.89813\n",
            "Epoch 81/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1931 - accuracy: 0.9205 - val_loss: 0.3961 - val_accuracy: 0.8565\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.89813\n",
            "Epoch 82/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2366 - accuracy: 0.9283 - val_loss: 0.3770 - val_accuracy: 0.8565\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.89813\n",
            "Epoch 83/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2072 - accuracy: 0.9166 - val_loss: 0.3812 - val_accuracy: 0.8295\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.89813\n",
            "Epoch 84/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2360 - accuracy: 0.9098 - val_loss: 0.4185 - val_accuracy: 0.8316\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.89813\n",
            "Epoch 85/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1654 - accuracy: 0.9423 - val_loss: 0.3096 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.89813\n",
            "Epoch 86/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1927 - accuracy: 0.9224 - val_loss: 0.3358 - val_accuracy: 0.8503\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.89813\n",
            "Epoch 87/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2021 - accuracy: 0.9199 - val_loss: 0.3395 - val_accuracy: 0.8545\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.89813\n",
            "Epoch 88/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1858 - accuracy: 0.9287 - val_loss: 0.3195 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.89813\n",
            "Epoch 89/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1971 - accuracy: 0.9223 - val_loss: 0.3268 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.89813\n",
            "Epoch 90/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1436 - accuracy: 0.9517 - val_loss: 0.3261 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.89813\n",
            "Epoch 91/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1681 - accuracy: 0.9406 - val_loss: 0.2512 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00091: val_accuracy improved from 0.89813 to 0.90644, saving model to mymodel2_91.h5\n",
            "Epoch 92/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2284 - accuracy: 0.9171 - val_loss: 0.3905 - val_accuracy: 0.8565\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.90644\n",
            "Epoch 93/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1701 - accuracy: 0.9343 - val_loss: 0.3102 - val_accuracy: 0.8794\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.90644\n",
            "Epoch 94/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1541 - accuracy: 0.9309 - val_loss: 0.2335 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00094: val_accuracy improved from 0.90644 to 0.93347, saving model to mymodel2_94.h5\n",
            "Epoch 95/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1769 - accuracy: 0.9342 - val_loss: 0.3677 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93347\n",
            "Epoch 96/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1831 - accuracy: 0.9412 - val_loss: 0.3416 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93347\n",
            "Epoch 97/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.2806 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93347\n",
            "Epoch 98/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 0.3013 - val_accuracy: 0.8753\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93347\n",
            "Epoch 99/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1674 - accuracy: 0.9389 - val_loss: 0.2691 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93347\n",
            "Epoch 100/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1668 - accuracy: 0.9358 - val_loss: 0.2180 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93347\n",
            "Epoch 101/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1000 - accuracy: 0.9703 - val_loss: 0.2798 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.93347\n",
            "Epoch 102/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1234 - accuracy: 0.9578 - val_loss: 0.2917 - val_accuracy: 0.8877\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.93347\n",
            "Epoch 103/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1133 - accuracy: 0.9586 - val_loss: 0.2977 - val_accuracy: 0.8940\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.93347\n",
            "Epoch 104/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1118 - accuracy: 0.9614 - val_loss: 0.5298 - val_accuracy: 0.8524\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.93347\n",
            "Epoch 105/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1269 - accuracy: 0.9549 - val_loss: 0.2407 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.93347\n",
            "Epoch 106/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1126 - accuracy: 0.9608 - val_loss: 0.2238 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.93347\n",
            "Epoch 107/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2358 - accuracy: 0.9134 - val_loss: 0.3495 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.93347\n",
            "Epoch 108/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1737 - accuracy: 0.9374 - val_loss: 0.2629 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.93347\n",
            "Epoch 109/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1322 - accuracy: 0.9534 - val_loss: 0.3282 - val_accuracy: 0.8877\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.93347\n",
            "Epoch 110/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1397 - accuracy: 0.9442 - val_loss: 0.2827 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.93347\n",
            "Epoch 111/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1414 - accuracy: 0.9461 - val_loss: 0.2087 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.93347\n",
            "Epoch 112/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0994 - accuracy: 0.9676 - val_loss: 0.1861 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.93347\n",
            "Epoch 113/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0946 - accuracy: 0.9653 - val_loss: 0.2679 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.93347\n",
            "Epoch 114/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1021 - accuracy: 0.9654 - val_loss: 0.2609 - val_accuracy: 0.8898\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.93347\n",
            "Epoch 115/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0892 - accuracy: 0.9609 - val_loss: 0.2984 - val_accuracy: 0.9023\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.93347\n",
            "Epoch 116/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1158 - accuracy: 0.9643 - val_loss: 0.1950 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.93347\n",
            "Epoch 117/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1163 - accuracy: 0.9569 - val_loss: 0.2654 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.93347\n",
            "Epoch 118/250\n",
            "31/31 [==============================] - 1s 40ms/step - loss: 0.0858 - accuracy: 0.9660 - val_loss: 0.1934 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.93347\n",
            "Epoch 119/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0895 - accuracy: 0.9643 - val_loss: 0.2228 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.93347\n",
            "Epoch 120/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1062 - accuracy: 0.9582 - val_loss: 0.1987 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.93347\n",
            "Epoch 121/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1179 - accuracy: 0.9482 - val_loss: 0.2065 - val_accuracy: 0.9168\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.93347\n",
            "Epoch 122/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0907 - accuracy: 0.9712 - val_loss: 0.2711 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.93347\n",
            "Epoch 123/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1824 - accuracy: 0.9309 - val_loss: 0.2179 - val_accuracy: 0.9085\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.93347\n",
            "Epoch 124/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1184 - accuracy: 0.9627 - val_loss: 0.2243 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.93347\n",
            "Epoch 125/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1013 - accuracy: 0.9590 - val_loss: 0.1966 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.93347\n",
            "Epoch 126/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2003 - accuracy: 0.9307 - val_loss: 0.2167 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.93347\n",
            "Epoch 127/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.2611 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.93347\n",
            "Epoch 128/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0907 - accuracy: 0.9684 - val_loss: 0.3023 - val_accuracy: 0.8877\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.93347\n",
            "Epoch 129/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0958 - accuracy: 0.9684 - val_loss: 0.1880 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.93347\n",
            "Epoch 130/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0728 - accuracy: 0.9776 - val_loss: 0.2637 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.93347\n",
            "Epoch 131/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.1708 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.93347\n",
            "Epoch 132/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.2230 - val_accuracy: 0.9085\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.93347\n",
            "Epoch 133/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0928 - accuracy: 0.9658 - val_loss: 0.2428 - val_accuracy: 0.9064\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.93347\n",
            "Epoch 134/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0824 - accuracy: 0.9745 - val_loss: 0.3064 - val_accuracy: 0.8919\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.93347\n",
            "Epoch 135/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0797 - accuracy: 0.9742 - val_loss: 0.1978 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.93347\n",
            "Epoch 136/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0614 - accuracy: 0.9761 - val_loss: 0.2062 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.93347\n",
            "Epoch 137/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0629 - accuracy: 0.9778 - val_loss: 0.2232 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.93347\n",
            "Epoch 138/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2110 - accuracy: 0.9306 - val_loss: 0.4935 - val_accuracy: 0.8524\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.93347\n",
            "Epoch 139/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2076 - accuracy: 0.9279 - val_loss: 0.2360 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.93347\n",
            "Epoch 140/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0879 - accuracy: 0.9661 - val_loss: 0.2322 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.93347\n",
            "Epoch 141/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0719 - accuracy: 0.9693 - val_loss: 0.1680 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.93347\n",
            "Epoch 142/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0738 - accuracy: 0.9649 - val_loss: 0.1457 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00142: val_accuracy improved from 0.93347 to 0.94179, saving model to mymodel2_142.h5\n",
            "Epoch 143/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0632 - accuracy: 0.9789 - val_loss: 0.1598 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.94179\n",
            "Epoch 144/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 0.1429 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.94179 to 0.95218, saving model to mymodel2_144.h5\n",
            "Epoch 145/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0550 - accuracy: 0.9774 - val_loss: 0.1758 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.95218\n",
            "Epoch 146/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0362 - accuracy: 0.9923 - val_loss: 0.1928 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.95218\n",
            "Epoch 147/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.95218\n",
            "Epoch 148/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0937 - accuracy: 0.9673 - val_loss: 0.2214 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.95218\n",
            "Epoch 149/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.2382 - accuracy: 0.9342 - val_loss: 0.2868 - val_accuracy: 0.8877\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.95218\n",
            "Epoch 150/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1391 - accuracy: 0.9695 - val_loss: 0.1944 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.95218\n",
            "Epoch 151/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1734 - accuracy: 0.9383 - val_loss: 0.1913 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 0.95218\n",
            "Epoch 152/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1027 - accuracy: 0.9658 - val_loss: 0.2152 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 0.95218\n",
            "Epoch 153/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1063 - accuracy: 0.9612 - val_loss: 0.3502 - val_accuracy: 0.8815\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 0.95218\n",
            "Epoch 154/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0831 - accuracy: 0.9681 - val_loss: 0.1993 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 0.95218\n",
            "Epoch 155/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0995 - accuracy: 0.9635 - val_loss: 0.2635 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 0.95218\n",
            "Epoch 156/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0737 - accuracy: 0.9721 - val_loss: 0.1548 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 0.95218\n",
            "Epoch 157/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0486 - accuracy: 0.9868 - val_loss: 0.1593 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 0.95218\n",
            "Epoch 158/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 0.2184 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 0.95218\n",
            "Epoch 159/250\n",
            "31/31 [==============================] - 1s 38ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.1970 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 0.95218\n",
            "Epoch 160/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.1828 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 0.95218\n",
            "Epoch 161/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.1706 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 0.95218\n",
            "Epoch 162/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0607 - accuracy: 0.9813 - val_loss: 0.1364 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 0.95218\n",
            "Epoch 163/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0837 - accuracy: 0.9694 - val_loss: 0.2791 - val_accuracy: 0.9044\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 0.95218\n",
            "Epoch 164/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0611 - accuracy: 0.9747 - val_loss: 0.1892 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 0.95218\n",
            "Epoch 165/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0802 - accuracy: 0.9715 - val_loss: 0.1926 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 0.95218\n",
            "Epoch 166/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0603 - accuracy: 0.9805 - val_loss: 0.1917 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 0.95218\n",
            "Epoch 167/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0424 - accuracy: 0.9893 - val_loss: 0.1429 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 0.95218\n",
            "Epoch 168/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0413 - accuracy: 0.9889 - val_loss: 0.1854 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 0.95218\n",
            "Epoch 169/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.2130 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 0.95218\n",
            "Epoch 170/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0587 - accuracy: 0.9797 - val_loss: 0.1870 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 0.95218\n",
            "Epoch 171/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0451 - accuracy: 0.9828 - val_loss: 0.1491 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 0.95218\n",
            "Epoch 172/250\n",
            "31/31 [==============================] - 1s 40ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.2023 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 0.95218\n",
            "Epoch 173/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.1679 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 0.95218\n",
            "Epoch 174/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 0.2327 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 0.95218\n",
            "Epoch 175/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0386 - accuracy: 0.9910 - val_loss: 0.1596 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 0.95218\n",
            "Epoch 176/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0640 - accuracy: 0.9771 - val_loss: 0.1615 - val_accuracy: 0.9376\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 0.95218\n",
            "Epoch 177/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0430 - accuracy: 0.9838 - val_loss: 0.1364 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00177: val_accuracy improved from 0.95218 to 0.95842, saving model to mymodel2_177.h5\n",
            "Epoch 178/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.1732 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 0.95842\n",
            "Epoch 179/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.1601 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 0.95842\n",
            "Epoch 180/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0657 - accuracy: 0.9772 - val_loss: 0.3121 - val_accuracy: 0.9127\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 0.95842\n",
            "Epoch 181/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0997 - accuracy: 0.9761 - val_loss: 0.2965 - val_accuracy: 0.9148\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 0.95842\n",
            "Epoch 182/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1404 - accuracy: 0.9607 - val_loss: 0.1336 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 0.95842\n",
            "Epoch 183/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0554 - accuracy: 0.9805 - val_loss: 0.1425 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 0.95842\n",
            "Epoch 184/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.1527 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 0.95842\n",
            "Epoch 185/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.1466 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 0.95842\n",
            "Epoch 186/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.1782 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 0.95842\n",
            "Epoch 187/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 0.1643 - val_accuracy: 0.9543\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 0.95842\n",
            "Epoch 188/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.1611 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 0.95842\n",
            "Epoch 189/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.2237 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 0.95842\n",
            "Epoch 190/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0589 - accuracy: 0.9799 - val_loss: 0.1755 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 0.95842\n",
            "Epoch 191/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 0.0955 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00191: val_accuracy improved from 0.95842 to 0.96258, saving model to mymodel2_191.h5\n",
            "Epoch 192/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.1121 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 0.96258\n",
            "Epoch 193/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.2055 - val_accuracy: 0.9252\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 0.96258\n",
            "Epoch 194/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0439 - accuracy: 0.9877 - val_loss: 0.1123 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 0.96258\n",
            "Epoch 195/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.1413 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 0.96258\n",
            "Epoch 196/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.1139 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 0.96258\n",
            "Epoch 197/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.1233 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 0.96258\n",
            "Epoch 198/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 0.1488 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 0.96258\n",
            "Epoch 199/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.2255 - val_accuracy: 0.9376\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 0.96258\n",
            "Epoch 200/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0655 - accuracy: 0.9730 - val_loss: 0.1339 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00200: val_accuracy improved from 0.96258 to 0.96466, saving model to mymodel2_200.h5\n",
            "Epoch 201/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.1562 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 0.96466\n",
            "Epoch 202/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0981 - accuracy: 0.9691 - val_loss: 0.1838 - val_accuracy: 0.9356\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 0.96466\n",
            "Epoch 203/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.1102 - accuracy: 0.9615 - val_loss: 0.1322 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 0.96466\n",
            "Epoch 204/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0742 - accuracy: 0.9692 - val_loss: 0.1139 - val_accuracy: 0.9543\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 0.96466\n",
            "Epoch 205/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0345 - accuracy: 0.9919 - val_loss: 0.1498 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 0.96466\n",
            "Epoch 206/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.1253 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 0.96466\n",
            "Epoch 207/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0371 - accuracy: 0.9852 - val_loss: 0.1132 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 0.96466\n",
            "Epoch 208/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.1667 - val_accuracy: 0.9543\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 0.96466\n",
            "Epoch 209/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0456 - accuracy: 0.9825 - val_loss: 0.1661 - val_accuracy: 0.9314\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 0.96466\n",
            "Epoch 210/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.1569 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 0.96466\n",
            "Epoch 211/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0385 - accuracy: 0.9903 - val_loss: 0.1467 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 0.96466\n",
            "Epoch 212/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.1040 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 0.96466\n",
            "Epoch 213/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.1421 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 0.96466\n",
            "Epoch 214/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.1407 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 0.96466\n",
            "Epoch 215/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.1886 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 0.96466\n",
            "Epoch 216/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.1341 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 0.96466\n",
            "Epoch 217/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.1166 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00217: val_accuracy improved from 0.96466 to 0.96674, saving model to mymodel2_217.h5\n",
            "Epoch 218/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.0933 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00218: val_accuracy improved from 0.96674 to 0.97089, saving model to mymodel2_218.h5\n",
            "Epoch 219/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0982 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 0.97089\n",
            "Epoch 220/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.1064 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 0.97089\n",
            "Epoch 221/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.1265 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 0.97089\n",
            "Epoch 222/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.2935 - val_accuracy: 0.9189\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 0.97089\n",
            "Epoch 223/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.2168 - accuracy: 0.9477 - val_loss: 0.4323 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 0.97089\n",
            "Epoch 224/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.1545 - accuracy: 0.9518 - val_loss: 0.1509 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 0.97089\n",
            "Epoch 225/250\n",
            "31/31 [==============================] - 1s 35ms/step - loss: 0.0822 - accuracy: 0.9696 - val_loss: 0.1351 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 0.97089\n",
            "Epoch 226/250\n",
            "31/31 [==============================] - 1s 40ms/step - loss: 0.0799 - accuracy: 0.9683 - val_loss: 0.1654 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 0.97089\n",
            "Epoch 227/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0826 - accuracy: 0.9747 - val_loss: 0.2308 - val_accuracy: 0.9106\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 0.97089\n",
            "Epoch 228/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0831 - accuracy: 0.9749 - val_loss: 0.1183 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 0.97089\n",
            "Epoch 229/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.1319 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 0.97089\n",
            "Epoch 230/250\n",
            "31/31 [==============================] - 1s 38ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0978 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 0.97089\n",
            "Epoch 231/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.1104 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 0.97089\n",
            "Epoch 232/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0191 - accuracy: 0.9955 - val_loss: 0.1112 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 0.97089\n",
            "Epoch 233/250\n",
            "31/31 [==============================] - 1s 38ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.1314 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 0.97089\n",
            "Epoch 234/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.1398 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 0.97089\n",
            "Epoch 235/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0284 - accuracy: 0.9880 - val_loss: 0.1580 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 0.97089\n",
            "Epoch 236/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0349 - accuracy: 0.9873 - val_loss: 0.1117 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 0.97089\n",
            "Epoch 237/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: 0.1038 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00237: val_accuracy improved from 0.97089 to 0.97297, saving model to mymodel2_237.h5\n",
            "Epoch 238/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.1094 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 0.97297\n",
            "Epoch 239/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0928 - val_accuracy: 0.9730\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 0.97297\n",
            "Epoch 240/250\n",
            "31/31 [==============================] - 1s 36ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0966 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 0.97297\n",
            "Epoch 241/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.1681 - val_accuracy: 0.9480\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 0.97297\n",
            "Epoch 242/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 0.1287 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 0.97297\n",
            "Epoch 243/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0887 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 0.97297\n",
            "Epoch 244/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.1467 - val_accuracy: 0.9501\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 0.97297\n",
            "Epoch 245/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.1003 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 0.97297\n",
            "Epoch 246/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0217 - accuracy: 0.9914 - val_loss: 0.1559 - val_accuracy: 0.9459\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 0.97297\n",
            "Epoch 247/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.1189 - val_accuracy: 0.9605\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 0.97297\n",
            "Epoch 248/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0138 - accuracy: 0.9943 - val_loss: 0.1114 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 0.97297\n",
            "Epoch 249/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.1231 - val_accuracy: 0.9584\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 0.97297\n",
            "Epoch 250/250\n",
            "31/31 [==============================] - 1s 37ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1115 - val_accuracy: 0.9709\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 0.97297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20d048e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "b_CXwAY1auGJ",
        "outputId": "9e1aeb82-91b9-4b96-9b95-06bc146c8aa9"
      },
      "source": [
        "y_pred=model.predict_classes(np.expand_dims(x_train, axis=3))\n",
        "rounded_labels=np.argmax(y_train, axis=1)\n",
        "con_mat = confusion_matrix(rounded_labels, y_pred)\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvefFAL2elj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "7c99c79c-e20c-4de7-9da2-623a506d7a87"
      },
      "source": [
        "y_pred=model.predict_classes(np.expand_dims(x_test, axis=3))\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "con_mat = confusion_matrix(rounded_labels, y_pred)\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD2WESg7KMAz"
      },
      "source": [
        "model.save('/content/drive/My Drive/ISEP/A3/DEEP LEARNING/Respiration Sound/model_with stretched_data.h5', save_format='h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xnQMPwLOpt3",
        "outputId": "4011aac4-a514-4e22-e1e2-9b5570316cb2"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/ISEP/A3/DEEP LEARNING/Respiration Sound/model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7ff47c6b4be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}